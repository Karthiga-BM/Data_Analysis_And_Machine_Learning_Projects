{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[Final] Combined Model.ipynb","provenance":[{"file_id":"1gWzd7ViInKxueAhZN33bywr47nLvTpLQ","timestamp":1598268701598}],"collapsed_sections":[],"mount_file_id":"1db9XQHsBKyGqOJ0HU9atsLkWRL6BI3I0","authorship_tag":"ABX9TyNERw4PtEiLSrjxCUi3hIUW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ac82fb6e00474995947125767990bcbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eba1ae595b584a7f855502a3f5dc7a9b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f683204f0e24b74803ac75b8470bd59","IPY_MODEL_bde5030508524a5e8808e44d363ba1c9"]}},"eba1ae595b584a7f855502a3f5dc7a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f683204f0e24b74803ac75b8470bd59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_00e101d297bc4f57aaa1a1a9295c7ea6","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":40,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":40,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b62362a437048d0bf0c7c69ee094264"}},"bde5030508524a5e8808e44d363ba1c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87401f47def041e596ed4eed26947944","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 40/40 [03:21&lt;00:00,  5.03s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4664fc304e854c98b3a27d5f8526f8f2"}},"00e101d297bc4f57aaa1a1a9295c7ea6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1b62362a437048d0bf0c7c69ee094264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87401f47def041e596ed4eed26947944":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4664fc304e854c98b3a27d5f8526f8f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"HfR8KKYxGvS_","colab_type":"code","colab":{}},"source":["#Copy dataset from Google drive to session storage\n","\n","zip_path_train = '/content/drive/My Drive/Python/SUBMISSION FOLDER/Final_test_data.zip'\n","!cp '{zip_path_train}' .\n","!unzip -q Final_test_data.zip\n","!rm Final_test_data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-A1qYr4yjU0","colab_type":"code","colab":{}},"source":["#to copy saved model of Caption Generator from drive to session storage\n","\n","path='/content/drive/My Drive/Python/Models_caption/model_rerun9.h5'\n","!cp '{path}' ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUa1lZinHsrf","colab_type":"code","colab":{}},"source":["#Copy Features extracted pickle file using Xception model from Google drive to session storage\n","\n","path='/content/drive/My Drive/Python/SUBMISSION FOLDER/features.p'\n","!cp '{path}' ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEUb7HpXH4b5","colab_type":"code","colab":{}},"source":["#Copy Tokenizer pickle file from Google drive to session storage\n","\n","path='/content/drive/My Drive/Python/SUBMISSION FOLDER/tokenizer.p'\n","!cp '{path}' ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cD_O4YhLK3wX","colab_type":"code","colab":{}},"source":["#Copy NSFW model from Google drive to session storage\n","\n","model_source= '/content/drive/My Drive/Python/SUBMISSION FOLDER/weights-improvement-VGG16 unlkd-09-0.89.hdf5'\n","!cp '{model_source}' ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l15Hmm3n9iEg","colab_type":"code","colab":{}},"source":["import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import argparse\n","\n","import string\n","import numpy as np\n","from PIL import Image\n","import os\n","from pickle import dump, load\n","import numpy as np\n","\n","from keras.applications.xception import Xception, preprocess_input\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.layers.merge import add\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n","\n","#Initial preprocessing to meet the needs of Image Captioning Model\n","\n","def preprocess_extract(filename, model):\n","        try:\n","            photo = Image.open(filename)    #Read Images\n","        except:\n","            print(\"Trouble opening image file, please ensure the path provided is correct\")\n","        photo = photo.resize((299,299))\n","        photo = np.array(photo)\n","        if photo.shape[2] == 4: \n","            photo = photo[..., :3]\n","        photo = np.expand_dims(photo, axis=0)\n","        photo = photo/127.5\n","        photo = photo - 1.0\n","        feature = model.predict(photo)    #Extract features using model\n","        return feature\n","\n","\n","def tokenize_words(integer, tokenizer):   #Tokenize words using pickle file\n","  for word, index in tokenizer.word_index.items():\n","      if index == integer:\n","          return word\n","  return None\n","\n","  \n","def caption_creator(model, tokenizer, photo, max_length):   #Final Captions are Created Here\n","    in_text = 'start'\n","    for i in range(max_length):\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        pred = model.predict([photo,sequence], verbose=0)\n","        pred = np.argmax(pred)\n","        word = tokenize_words(pred, tokenizer)    \n","        if word is None:\n","            break\n","        in_text += ' ' + word\n","        if word == 'end':\n","            break\n","    return in_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lczEsA1HPMp","colab_type":"code","colab":{}},"source":["#Filling Variables used For Captioning Model\n","\n","def generate_caption(filename):\n","  path = filename   #Image Path\n","  max_length = 32   #Max Length of Descriptions \n","  tokenizer = load(open(\"tokenizer.p\",\"rb\"))  #Insert Path for Tokenizer Pickle File\n","  model = load_model('model_rerun9.h5')       #Insert Path for Image Captioning Model\n","  model_xcept = Xception(include_top=False, pooling=\"avg\")  #Xception Model\n","  photo = preprocess_extract(path, model_xcept)  \n","  image = Image.open(path)                          \n","  caption = caption_creator(model, tokenizer, photo, max_length)  #Final Caption Creation\n","  print(\"\\n\\n\")\n","  print(caption)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_vrI4IAI5Kj","colab_type":"code","colab":{}},"source":["#Setting the Location of the Database\n","\n","test_root='/content/Final_test_data'   #Insert Final Dataset Path Here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nxMcYZqhJ3vB","colab_type":"code","colab":{}},"source":["from tqdm import tqdm_notebook as tqdm\n","import numpy as np\n","from keras.preprocessing import image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDQcgxpSIOZU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1598351849489,"user_tz":-60,"elapsed":514,"user":{"displayName":"Aayush Jain","photoUrl":"","userId":"02816052941629440884"}},"outputId":"4a5705ca-a2fd-4f1c-8343-66cd27abb104"},"source":["#Shuffling the Images and Making a NumPy Array of All the Images(NSFW + SAFE)\n","\n","test_files = np.array(os.listdir(test_root))\n","\n","for _ in range(5):\n","    np.random.shuffle(test_files)\n","\n","test_image_files = []\n","for image in test_files:\n","    test_image_files.append(os.path.join(test_root, image))\n","\n","test_image_files = np.array(test_image_files)\n","for _ in range(5): indexes = np.random.permutation(range(len(test_image_files)))\n","test_image_files = test_image_files[indexes]\n","test_image_files[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['/content/Final_test_data/3463034205_e541313038.jpg',\n","       '/content/Final_test_data/1412832223_99e8b4701a.jpg',\n","       '/content/Final_test_data/3422394336_e465f60b7c.jpg',\n","       '/content/Final_test_data/prefix_GantMan_0000B748-551C-4388-A4EC-B1C832324C6F.jpg.jpeg',\n","       '/content/Final_test_data/prefix_GantMan_00000A77-D61D-47FC-B4A6-934E1E5ED671.jpg.jpeg',\n","       '/content/Final_test_data/10815824_2997e03d76.jpg',\n","       '/content/Final_test_data/224026428_0165164ceb.jpg',\n","       '/content/Final_test_data/697582336_601462e052.jpg',\n","       '/content/Final_test_data/2672354635_3a03f76486.jpg',\n","       '/content/Final_test_data/3183875944_b2be694e06.jpg'], dtype='<U85')"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"RD6Up0nfJ-p5","colab_type":"code","colab":{}},"source":["#Declaring Variables Required By NSFW Filter\n","\n","IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 150, 150, 3, 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbAdroPLLMvy","colab_type":"code","colab":{}},"source":["from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUVjUAuOKCOX","colab_type":"code","colab":{}},"source":["#Loading NSFW Model\n","\n","model_xfer2=keras.models.load_model('/content/weights-improvement-VGG16 unlkd-09-0.89.hdf5')  #Insert NSFW Model Path Here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ol_KLvtENvey","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ac82fb6e00474995947125767990bcbb","eba1ae595b584a7f855502a3f5dc7a9b","7f683204f0e24b74803ac75b8470bd59","bde5030508524a5e8808e44d363ba1c9","00e101d297bc4f57aaa1a1a9295c7ea6","1b62362a437048d0bf0c7c69ee094264","87401f47def041e596ed4eed26947944","4664fc304e854c98b3a27d5f8526f8f2"],"output_embedded_package_id":"1g_5tlbOebyDVRxtzhrk0l8pQ2P6-VBmC"},"executionInfo":{"status":"ok","timestamp":1598352063629,"user_tz":-60,"elapsed":202103,"user":{"displayName":"Aayush Jain","photoUrl":"","userId":"02816052941629440884"}},"outputId":"72d6be0f-3581-4855-e821-1658b5360127"},"source":["#Preprocessing Images According to NSFW Model Needs And Prediction with Caption Generation\n","NSFW_img=0\n","from keras.preprocessing import image\n","for test_image in tqdm(test_image_files):\n","\n","      img = image.load_img(test_image, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n","      x = image.img_to_array(img)\n","      x = np.expand_dims(x, axis=0)\n","      x /= 255.0\n","\n","      images_list = np.vstack([x])\n","      classes = model_xfer2.predict(images_list, batch_size=10)\n","      prob = classes[0]\n","      actual_name = (test_image.split(os.path.sep)[-2].split('.')[0]).upper() \n","      pred_name = 'SAFE' if (prob >= 0.5) else 'NSFW'\n","      is_correct = (pred_name =='SAFE')\n","      if is_correct:\n","        #print(test_image)\n","        generate_caption(test_image)\n","        plt.imshow(img)\n","        plt.show(img)\n","        print('The above image is '+pred_name+' and does not contain any NSFW element')\n","        print('NSFW Images Omitted='+str(NSFW_img))\n","      else:\n","        NSFW_img=NSFW_img+1"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"maoJyBfLRw5v","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}